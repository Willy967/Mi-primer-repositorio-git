{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demostraci√≥n del Pipeline de Procesamiento de Texto\n",
    "## Autora: Pagella, Sabrina\n",
    "\n",
    "En este notebook se muestra paso a paso c√≥mo funciona un pipeline b√°sico de procesamiento de texto, desde la limpieza hasta la obtenci√≥n de las palabras m√°s frecuentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texto de prueba\n",
    "texto = \"\"\"ChatGPT es una herramienta de inteligencia artificial que permite conversar con una IA. \n",
    "Puede ayudar a escribir, programar, estudiar o resolver dudas. \n",
    "Tambi√©n sirve para aprender c√≥mo funcionan los modelos de lenguaje.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£ Funci√≥n: limpiar texto (eliminar may√∫sculas y signos)\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z√°√©√≠√≥√∫√º√±\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "texto_limpio = clean_text(texto)\n",
    "print(texto_limpio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£ Funci√≥n: tokenizar palabras (separar en lista)\n",
    "def tokenize_words(text):\n",
    "    return text.split()\n",
    "\n",
    "tokens = tokenize_words(texto_limpio)\n",
    "print(tokens[:10])  # muestra las primeras 10 palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3Ô∏è‚É£ Funci√≥n: eliminar stopwords (palabras vac√≠as como 'de', 'la', 'que')\n",
    "stopwords = ['de', 'la', 'el', 'que', 'una', 'con', 'para', 'c√≥mo', 'los', 'en']\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word not in stopwords]\n",
    "\n",
    "tokens_filtrados = remove_stopwords(tokens)\n",
    "print(tokens_filtrados[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4Ô∏è‚É£ Funci√≥n: frecuencia simple de palabras\n",
    "from collections import Counter\n",
    "\n",
    "def simple_freq(tokens):\n",
    "    return Counter(tokens)\n",
    "\n",
    "frecuencias = simple_freq(tokens_filtrados)\n",
    "print(frecuencias.most_common(5))  # Top 5 palabras m√°s frecuentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß† Explicaci√≥n de cada paso\n",
    "1. **clean_text:** elimina may√∫sculas, tildes raras y signos de puntuaci√≥n.\n",
    "2. **tokenize_words:** convierte el texto en una lista de palabras.\n",
    "3. **remove_stopwords:** borra palabras comunes sin mucho significado.\n",
    "4. **simple_freq:** cuenta cu√°ntas veces aparece cada palabra.\n",
    "\n",
    "As√≠ se obtiene un resumen r√°pido de qu√© palabras son m√°s importantes o repetidas en un texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ú® Reflexi√≥n final sobre ChatGPT\n",
    "\n",
    "**¬øLo usaste?** S√≠, lo us√© para entender los pasos y generar el c√≥digo del pipeline.\n",
    "\n",
    "**¬øQu√© te corrigi√≥?** Me ayud√≥ a entender el orden correcto de las funciones y a usar expresiones regulares para limpiar texto.\n",
    "\n",
    "**¬øQu√© aprendiste?** Aprend√≠ c√≥mo se procesa un texto paso a paso y c√≥mo obtener informaci√≥n √∫til como las palabras m√°s frecuentes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
